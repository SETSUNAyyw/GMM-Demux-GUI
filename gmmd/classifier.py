import numpy as np

import pandas as pd
from scipy import stats
from sys import argv
from sklearn.mixture import GaussianMixture
import os
from math import log2

from gmmd import multi
from gmmd import compute

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt


def obtain_arrays(data, path = None):
    """Obtain post probabilities of the high and low Gaussian distribution.

    :param data: CLR-transformed HTO matrix.
    :type data: :class:`pandas.DataFrame`

    :return: Post probabilities of higher mean, post probabilities of lower mean.
    :rtype: :class:`list`, :class:`list`

    """
    gmm = []
    high_array = []
    low_array = []
    hto_array = data.columns

    for i in range(data.shape[1]):
        X = data.iloc[:,i].values[:, np.newaxis]

        # GMM values
        gmm.append(GaussianMixture(2, random_state=0).fit(X))
        x = np.linspace(-6, 6, 1000)[:, np.newaxis]
        logprob = gmm[-1].score_samples(x)
        responsibilities = gmm[-1].predict_proba(x)
        pdf = np.exp(logprob)
        pdf_individual = responsibilities * pdf[:, np.newaxis]

        # Plot probabilities distribution
        if (not path):
            path = "/tmp/.gmm-demux/"
        if (not os.path.exists(path)):
            os.makedirs(path)
        # print(len(pdf_individual))
        plt.clf()
        plt.plot(x, pdf_individual)
        plt.savefig(os.path.join(path, f"pdf_{hto_array[i]}.png"))

        # print(gmm[-1].means_)

        # Extract prob
        high_idx = np.argmax(gmm[-1].means_, axis=0)[0]
        post_prob = gmm[-1].predict_proba(X)
        high_array.append(post_prob[np.arange(post_prob.shape[0]), np.full(post_prob.shape[0], high_idx)])
        low_array.append(np.full(post_prob.shape[0], 1.0) - high_array[-1])

    return high_array, low_array


# def classify_drops(base_bv_array, high_array, low_array, sample_num, GEM_num, index, column):
def classify_drops(base_bv_array, high_array, low_array, data):
    """Calculate confidence of all GEM cells.

    :param base_bv_array: Binary array with all combinations of cells, generated by :func:`gmmd.compute.obtain_base_bv_array`.
    :type base_bv_array: :class:`list`
    :param high_array: Post probabilities of the higher mean Gaussian distribution, generated by :func:`gmmd.classifier.obtain_arrays`.
    :type high_array: :class:`list`
    :param low_array: Post probabilities of the lower mean Gaussian distribution, generated by :func:`gmmd.classifier.obtain_arrays`.
    :type low_array: :class:`list`
    :param data: CLR-transformed HTO matrix.
    :type data: :class:`pandas.DataFrame`

    :return: Classified results and confidence, all class names.
    :rtype: :class:`pandas.DataFrame`, :class:`list`

    """
    index = data.index
    column = data.columns.values
    sample_num = len(column)
    GEM_num = len(index)
    classified_ary = np.full(GEM_num, 0)
    classified_name_ary = np.full(GEM_num, None)
    confidence_ary = np.full(GEM_num, 0.0)

    class_name_array = ["negative"]
    all_idx_ary = []

    for i in range(sample_num):
        all_idx_ary.append(i)

    # Detailed classification
    for i in range(len(base_bv_array)):
        bv = base_bv_array[i]
        high_idx_ary = []
        name = ""

        for j in range(sample_num):
            if compute.check_set_bit(bv, j):
                high_idx_ary.append(j)
                name += (column[j] + "-")
        
        if name != "":
            name = name[:-1]
            class_name_array.append(name)

        tmp_confidence_ary = multi.compute_confidence(high_array, low_array, high_idx_ary, all_idx_ary)
        update_idx = (tmp_confidence_ary > confidence_ary).nonzero()[0]
        confidence_ary[update_idx] = tmp_confidence_ary[update_idx]
        classified_ary[update_idx] = i
        classified_name_ary[update_idx] = class_name_array[i]


    GMM_array = np.column_stack(tuple([classified_ary, classified_name_ary, confidence_ary]))
    GMM_full_df = pd.DataFrame(data=GMM_array, index = index, columns = ["Cluster_id", "Class_name", "Confidence"])
    GMM_full_df["Cluster_id"] = GMM_full_df["Cluster_id"].astype(int)

    return GMM_full_df, class_name_array


def read_full_classify_result(path):
    """Read classification result from ``path``.

    :param path: Path to ``GMM_full.csv`` and ``GMM_full.config``.
    :type path: :class:`String`

    :return: Classification result, number of samples, class names, sample names.
    :rtype: :class:`pandas.DataFrame`, :class:`list`, :class:`list`, :class:`list`

    """
    # print(path)
    classify_file_name = os.path.join(path, "GMM_full.csv")
    config_file_name = os.path.join(path, "GMM_full.config")

    full_df = pd.read_csv(classify_file_name, index_col = 0)
    config_df = pd.read_csv(config_file_name, header=None)
    confidence_threshold = float(config_df.iat[0, 1])
    config_df = config_df.drop(labels = 0, axis = 0)

    sample_num = int(log2(config_df.shape[0]))

    return full_df, sample_num, config_df.index.tolist(), [config_df.iat[i + 1, 1] for i in range(sample_num)], confidence_threshold


# Store full classification result
def store_full_classify_result(data, class_name_array, confidence_threshold, path):
    """Store the full classification result in ``{path}/GMM_full.csv``. The result will contain all cluster ids, and the corresponding names can be found in ``{path}/GMM_full.config``.

    :param data: Classification result, generated by :func:`gmmd.classifier.classify_drops`.
    :type data: :class:`pandas.DataFrame`
    :param class_name_array: All class names, generated by :func:`gmmd.classifier.classify_drops`.
    :type class_name_array: :class:`list`
    :param path: File path to store the result.
    :type path: :class:`String`

    """
    if not os.path.exists(path):
        os.makedirs(path)

    classify_file_name = os.path.join(path, "GMM_full.csv")
    config_file_name = os.path.join(path, "GMM_full.config")

    data.to_csv(classify_file_name)

    with open(config_file_name, 'w') as f:
        f.write(f"threshold, {confidence_threshold}\n")
        for i in range(len(class_name_array)):
            f.write("%s, %s\n" % (i, class_name_array[i]))


# Store simplified classification result
def store_simplified_classify_result(data, class_name_array, path, sample_num, confidence_threshold):
    """Store the simplified classification result in ``{path}/GMM_simplified.csv``. The result will combine MSM classifications and mark those with confidence under the threshold as unclear. The corresponding cluster names can be found in ``{path}/GMM_simplified.config``.

    :param data: Classification result, generated by :func:`gmmd.classifier.classify_drops`.
    :type data: :class:`pandas.DataFrame`
    :param class_name_array: All class names, generated by :func:`gmmd.classifier.classify_drops`.
    :type class_name_array: :class:`list`
    :param path: File path to store the result.
    :type path: :class:`String`
    :param sample_num: Number of the HTO samples.
    :type sample_num: :class:`int`
    :param confidence_threshold: Confidence threshold.
    :type confidence_threshold: :class:`float`

    :return: Simplified classification result.
    :rtype: :class:`pandas.DataFrame`

    """
    simplified_df = data.copy()
    #print(simplified_df)
    MSM_idx = data.index[(data["Cluster_id"] > sample_num).to_numpy().nonzero()[0]]
    # print(MSM_idx)
    simplified_df.loc[MSM_idx, "Cluster_id"] = sample_num + 1
    unclear_idx = data.index[(data["Confidence"] < confidence_threshold).to_numpy().nonzero()[0]]
    #print(unclear_idx)
    simplified_df.loc[unclear_idx, "Cluster_id"] = sample_num + 2
    #print(simplified_df)

    if path != None:
        if not os.path.exists(path):
            os.makedirs(path)

        classify_file_name = os.path.join(path, "GMM_simplified.csv")
        config_file_name = os.path.join(path, "GMM_simplified.config")

        simplified_df.to_csv(classify_file_name)

        simplified_name_array = [class_name_array[i] for i in range(sample_num + 1)]
        simplified_name_array.append("MSM")
        simplified_name_array.append("Unclear")

        with open(config_file_name, 'w') as f:
            for i in range(len(simplified_name_array)):
                f.write("%s, %s\n" % (i, simplified_name_array[i]))

    return simplified_df


def purify_droplets(data, confidence_threshold):
    """Remove empty droplets or with confidence under the threshold.

    :param data: Classification result, generated by :func:`gmmd.classifier.classify_drops`.
    :type data: :class:`pandas.DataFrame`
    :param confidence_threshold: Confidence threshold.
    :type confidence_threshold: :class:`float`

    :return: Purified classification result.
    :rtype: :class:`pandas.DataFrame`

    """
    drop_idx = data.index[((data["Confidence"] < confidence_threshold) | (data["Cluster_id"] == 0)).to_numpy().nonzero()[0]]
    purified_df = data.drop(drop_idx)
    return purified_df


def count_bad_droplets(data, confidence_threshold):
    """Count empty droplets with or confidence under the threshold.

    :param data: Classification result, generated by :func:`gmmd.classifier.classify_drops`.
    :type data: :class:`pandas.DataFrame`
    :param confidence_threshold: Confidence threshold.
    :type confidence_threshold: :class:`float`

    :return: Counts of negative droplets, counts of unclear droplets.
    :rtype: :class:`list`, :class:`list`

    """
    negative_num = (data["Cluster_id"] == 0).sum()
    unclear_num = (data["Confidence"] < confidence_threshold).sum()
    return negative_num, unclear_num


def obtain_SSD_list(data, sample_num, class_id_ary = None):
    """Return GEM barcodes that are SSDs.

    :param data: Purified classification result, generated by :func:`gmmd.classifier.purify_droplets`.
    :type data: :class:`pandas.DataFrame`
    :param sample_num: Number of HTO samples.
    :type sample_num: :class:`int`
    :param class_id_ary: To extract specific class, provide an id array.
    :type class_id_ary: :class:`list`, Default = ``None``

    :rtype: :class:`list`

    :Example:
        >>> obtain_SSD_list(data, 4, [5, 11])
        
        Returns SSDs that contain cluster id 5 or 11.

        e.g. HTO samples are ``HTO_1, HTO_2, HTO_3, HTO_4``, 
        then cluster id ``5`` will be ``HTO_1+HTO_2``, and ``11`` will be ``HTO_1+HTO_2+HTO_3``.

    """
    if class_id_ary is not None:
        SSD_idx = []
        for class_id in class_id_ary:
            SSD_idx.extend(data.index[data["Cluster_id"] == class_id])
    else:
        SSD_idx = data.index[data["Cluster_id"] <= sample_num]

    return SSD_idx


def obtain_MSM_list(data, sample_num, idx_list = None):
    """Return GEM barcodes that are MSMs.

    :param data: Simplified classification result, generated by :func:`gmmd.classifier.store_simplified_classify_result`.
    :type data: :class:`pandas.DataFrame`
    :param sample_num: Number of HTO samples.
    :type sample_num: :class:`int`
    :param idx_list: List of index to extract.
    :type idx_list: :class:`list`, Default = ``None``

    :rtype: :class:`list`

    """
    if idx_list == None:
        MSM_idx = data.index[data["Cluster_id"] == sample_num + 1]
    else:
        selected_df = data.loc[idx_list]
        MSM_idx = selected_df.index[selected_df["Cluster_id"] == sample_num + 1]

    return MSM_idx


def count_by_class(data, base_bv_array):
    """Obtain list of count by class.

    :param data: Purified classification result, generated by :func:`gmmd.classifier.purify_droplets`.
    :type data: :class:`pandas.DataFrame`
    :param base_bv_array: Binary array with all combinations of cells, generated by :func:`gmmd.compute.obtain_base_bv_array`.
    :type base_bv_array: :class:`list`

    :return: List of count by class.
    :rtype: :class:`list`

    """
    count_ary = []
    for i in range(1, len(base_bv_array) + 1):
        count_ary.append((data["Cluster_id"] == i).sum())

    return count_ary


def get_SSD_count_ary(data, SSD_idx, sample_num):
    """Obtain SSD count list.

    :param data: Purified classification result, generated by :func:`gmmd.classifier.purify_droplets`.
    :type data: :class:`pandas.DataFrame`
    :param SSD_idx: SSD list, generated by :func:`gmmd.classifier.obtain_SSD_list`.
    :type SSD_idx: :class:`list`
    :param sample_num: Number of samples.
    :type sample_num: :class:`int`

    :return: List of SSD count.
    :rtype: :class:`list`

    """
    SSD_df = data.loc[SSD_idx,:]
    SSD_count_ary = []

    for i in range(1, sample_num + 1):
        SSD_count_ary.append((SSD_df["Cluster_id"] == i).sum())

    return SSD_count_ary


